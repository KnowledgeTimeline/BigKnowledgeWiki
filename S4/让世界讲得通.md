# 让世界讲得通

蒂姆·哈福德（Tim Harford）出了一本书，叫《让世界讲得通：十个数字思维法则》（How to Make the World Add Up: Ten Rules for Thinking Differently About Numbers），说的是统计学的一个侧面应用，有新意。

<div align="center">
  <img src="S4/imgs/page2116_img001.png" alt="《让世界讲得通：十个数字思维法则》（How to Make the World Add Up: Ten Rules for Thinking Differently About Numbers）" width="300" />
  <p style="margin: 5px 0; font-size: 14px; color: #666;">《让世界讲得通：十个数字思维法则》（How to Make the World Add Up: Ten Rules for Thinking Differently About Numbers）</p>
</div>

蒂姆·哈福德应该是你非常熟悉的一位经济学作家，畅销书《卧底经济学》系列就是他写的。我们专栏专门连载解读过他的《塑造现代经济的五十个发明》和《混乱》两本书。这本《让世界讲得通》是 2020 年 9 月 17 日出版的，它的主题是怎样通过数字，使用统计学的思维，理解现代世界。

这本书在技术上很柔软，一个公式都没有，所以你完全不用担心数学。但是在思想上，哈福德有个强硬的立场。

## 1：统计学的武德

这个立场就是统计学是用来帮你发现真相的，而不是用来捣乱的。

此话怎讲呢？我看现在各路武术学校招到新生，在正式学功夫之前都要先讲讲“武德”。咱们效法这个做法，第一讲先说说统计学的武德。

<center><strong>*</strong></center>

“用数据思考”是个老话题，但是你注意到没有，关于这个话题，有两个截然相反的说法。一个叫“数据不会说谎”，一个叫“统计数据会说谎”。这两个说法都已经被用作书名了。《数据不说谎》（作者是“城市数据团”）是一本 2017 年出版的讲大数据的书；《统计数据会说谎》（How to Lie with Statistics）则是一本 1954 年出版的经典之作，是每一个想要谈论统计学的作者都听说过的书。

《统计数据会说谎》这本书里的各种典故你可能已经耳熟能详：数据采样不一定有代表性、平均值不能反映一个群体的整体水平、相关性不等于因果性，等等，这些观点被后来无数的书反复提及。你应该会相信，所谓“数据不说谎”，听起来很像是“大数据”概念的广告词；而“统计数据会说谎”才是潜规则。

那然后呢？统计数据会说谎，那我们怎么才能知道真相呢？

哈福德一开篇就爆了个料：《统计数据会说谎》那本书的作者，达莱尔·哈夫（Darrell Huff），是个没有武德的人。

上世纪六十年代，经济学家和医生们联手，已经取得了非常强硬的统计学证据，证明吸烟会导致肺癌。1965 年，美国国会考虑立法，要求所有香烟盒都必须印上“吸烟有害健康”的警告字样。哈夫因为《统计数据会说谎》这本书成了当时最著名的统计学人物，被请到国会作证。国会议员问哈夫，吸烟和疾病，是不是仅仅是统计意义上的相关性，而不能说明因果关系？

哈夫明确回答，他认为是的。

而事实是此前大量的研究不仅仅是发现了吸烟跟肺癌之间的相关性，更是用非常缜密的方法，包括大规模长期跟踪研究，排除了各种别的可能性，证明其中有明确因果关系。哈夫不顾那些研究，上来就一句“相关不等于因果”，简直是个统计学小丑。谁都知道相关不等于因果，可你如果抱着这句话拒绝相信一切因果关系，看什么都是巧合，那你就什么决策也不能做，你就是是非不分。

<center><strong>*</strong></center>

学习和思考不是为了愤世嫉俗，你不能学了很多知识就学会一个这也不信那也不信。我们在《科学思考者》中说过，科学思考是为了明辨是非 —— 这也正是哈福德的强硬立场。然而现在有很多人，很多机构，恰恰不想让你明辨是非。

最近有个美剧叫《无所作为》（The Undoing，2020）不知道你看了没有。是一个关于谋杀和出轨的故事，剧中有一个设定很有意思。女主人公，也就是谋杀案嫌疑人的妻子，是非常有钱的人，她请了一位律师。你可以想见有钱人的律师可能是为客户，而不是为正义服务的，这个律师就是这样的。

但是律师告诉女主人公，她做的不是抹去（undo）真相。真相就是真相，谁也抹不掉。她做的是制造垃圾信息，从而让真相变得模糊，从而让法庭做出错误判断。

<div align="center">
  <img src="S4/imgs/page2119_img001.png" alt="律师的工作是生产怀疑" width="400" />
</div>

这个律师的工作是生产怀疑。

而生产怀疑，恰恰是当初烟草公司面对吸烟导致癌症这个指控时候的应对方案。烟草公司也请了人做研究，他们不可能证明“吸烟对健康无害”，但是他们能对“吸烟导致癌症”这个结论提出质疑。他们也会提出一些事实，来说明那些统计结论不可靠，从而把水搅浑。

这其实就是我们说过的“用事实误导”。这是现代社会通用的做法。这招为什么特别好使呢？哈福德讲了一个有意思的故事。

<center><strong>*</strong></center>

十七世纪的约翰内斯·维米尔（Johannes Vermeer）是荷兰历史上最著名的画家。二十世纪的艺术史专家亚伯拉罕·布雷迪乌斯（Abraham Bredius）是研究维米尔的权威。1937 年，布雷迪乌斯亲自鉴定，一幅刚刚被发现的维米尔画作，叫《以马忤斯的晚餐》，是维米尔的真迹。他的鉴定词中有一句是这么说的：

“这幅画跟维米尔所有其他的画作都很不同，然而画中每一英寸都是真正的维米尔。” 

<div align="center">
  <img src="S4/imgs/page2120_img001.png" alt="Christ at Emmaus" width="700" />
</div>

就是这幅画(Christ at Emmaus)。

你是不是觉得这句话有点怪呢？这有一位三百年前的大师，他的每一幅作品我们都熟悉。现在突然冒出了一幅号称是他的画，而这幅画跟我们已知的他每一幅画都很不同，这幅画的技法和内容都比不上维米尔其他的作品……那你凭什么相信这幅是真作呢？

而且还不只是这一幅。后来又陆陆续续冒出了好几幅新发现的维米尔真迹。你是不是觉得这很可疑呢？布雷迪乌斯完全没有怀疑。

1940 年，纳粹德国占领了荷兰。荷兰商人疯狂收购维米尔的作品，生怕它们落入纳粹之手。然而还是有一幅维米尔的画 —— 正是新发现的这批画中的一幅—— 叫《耶稣和通奸的女人》，被卖给了纳粹二号头目，赫尔曼·戈林。卖画的人叫汉·范米格伦（Han van Meegeren）。

1945 年荷兰解放，范米格伦以叛国罪被逮捕。范米格伦为了自保，说出了一个秘密。原来所有那些新发现的维米尔作品，都是他伪造的。

<div align="center">
  <img src="S4/imgs/page2121_img001.png" alt="范米格伦在受审" width="500" />
  <p style="margin: 5px 0; font-size: 14px; color: #666;">范米格伦在受审</p>
</div>

荷兰政府赶紧找科学家鉴定，果然如此。画的颜料中有酚醛树脂和钴蓝，这些东西维米尔那个年代根本就没有。范米格伦还专门在监狱中现场仿画了一幅维米尔，证明自己确实有这个能力。至此真相大白。范米格伦被免除了叛国罪，仅仅以伪造罪被判处一年徒刑。

可是当初那位研究维米尔的专家布雷迪乌斯，为啥判断失误了呢？

因为他希望那些画是真的。

<center><strong>*</strong></center>

布雷迪乌斯有个情感弱点。世间流传的维米尔的宗教题材画作只有两幅，其中一幅就在布雷迪乌斯自己手里。另一幅，也是维米尔唯一一幅描写了《圣经》中场景的画作，曾经被布雷迪乌斯错误地鉴定为是假画。后来所有同行都反对他的观点，这是他的一个学术污点。难不成维米尔的宗教画只有你手里这幅是真的，别的都是假的？布雷迪乌斯绝对不能再犯一次这样的错误。

所以布雷迪乌斯一直都在等待一个能证明自己的学术公正性的机会。而且布雷迪乌斯还有个理论，他猜测维米尔年轻时代曾经受到过意大利画家卡拉瓦乔的影响，但是他没有证据。而范米格伦伪造的这幅《以马忤斯的晚餐》，正好是一幅宗教画，而且画的构图正好是模仿了卡拉瓦乔 —— 这简直就是给布雷迪乌斯量身定制的。

这不是巧合。范米格伦完全知道布雷迪乌斯在等待这样一幅画。而且范米格伦下了大功夫。他模仿了维米尔的笔法。他用的画布是十七世纪的，上面有真实的裂纹。他自己做实验发明了一种让颜料变得很干的技术，让你用酒精擦拭不会掉色 —— 当时的人都认为，只有老画才是这样的。范米格伦留下了只有内行才能看懂的线索，所以尽管那幅画本身的水平比维米尔差得多，布雷迪乌斯还是相信了。

布雷迪乌斯陷入了愿望思维。

<center><strong>*</strong></center>

我们专栏讲过愿望思维（wishful thinking）。因为你希望这是真的，所以你会相信这是真的。哈福德在书中列举了很多有关愿望思维的研究结果。这些研究的一大主题是，越是高学历的人、越是专业人士，越有可能对不符合自己愿望的证据视而不见，越善于把反方向的证据往正的方向解释。

对此你不会感到意外，理性很多时候是专门为情绪服务的。但是你对愿望思维的警惕可能远远不够。范米格伦伪造维米尔画作那个案件接下来的发展可能更值得我们深思。

荷兰人免除了范米格伦的叛国罪，这合理吗？事实上范米格伦真的叛国了。他跟纳粹的关系不是一般的好，在荷兰人都当了亡国奴、连饭都吃不饱的时候，范米格伦却过着花天酒地的生活。他专门写了一本赞美纳粹精神的书，还把书签名，送给了希特勒。这本书还被人们从希特勒的图书馆里找到了。如果这都不叫叛国，到底什么叫叛国？

然而荷兰人把范米格伦当做了英雄。为啥呢？因为荷兰人需要一个英雄！纳粹占领荷兰期间，荷兰人没有什么像样的抵抗，荷兰缺英雄。我理解这就如同八国联军攻占北京，中国人的唯一亮点是出了个名妓赛金花，敢跟德国人谈，用粮食换取放过百姓 —— 范米格伦居然用假画骗了戈林的钱？英雄啊！

荷兰人也陷入了愿望思维。

<center><strong>*</strong></center>

这个道理是如果你陷入愿望思维，再给你多少数据也没用。你的愿望，你的情感，是你的弱点。所以如果你想要用统计学了解真相，就必须先克制自己的情感。

但这可不是说让你做个没有情感的人。好消息是有好几个研究证明，只要你能让人心平气和下来，人们分辨哪个是靠谱媒体哪个是假新闻，哪个证据可靠哪个证据不可靠的能力是很强的。一边是科学家共识一边是中老年朋友圈传闻，是你你信哪个？其实你都明白。

哈福德认为，人们之所以在社交网络转发假新闻、激烈地发出错误评论，并不是因为这些人真不懂，而是因为他们控制不住自己的情绪。只要你做动作之前能先沉默一分钟，考虑清楚，你其实知道是非。

所以 **<span style="color: #E87321;">统计学的第一条法则是倾听自己的情绪。不要因为不喜欢一个数字就忽略这个数字，也不要因为喜欢一条证据就强化这条证据。</span>**

如果你的目的仅仅是想证明自己正确，这一切另当别论，你可以琢磨琢磨《统计数据会说谎》，研究研究范米格伦是怎么发家的。

但我们作为士，总要讲点武德，我们需要知道事情的真相到底是什么。

> **划重点**
> 
> 1.如果你陷入愿望思维，再给你多少数据也没用。你的愿望，你的情感，是你的弱点。所以如果你想要用统计学了解真相，就必须先克制自己的情感。
> 2.统计学的第一条法则是倾听自己的情绪。不要因为不喜欢一个数字就忽略这个数字，也不要因为喜欢一条证据就强化这条证据。

## 2：虫的视角和鸟的视角

2020 年新冠疫情在美国肆虐，统计数字非常可怕。不幸的是我正好住在美国，幸运的是我收到了很多来自国内亲友的问候和帮助。他们寄来了防疫物资，担心我和家人的健康、乃至人身安全，还想让我回国避难。

我的生活确实受到了疫情的强烈影响。孩子们都停课了，能在家上班都在家上班，所有聚会都取消了，餐馆和超市都去的很少，最恐慌的时候街上的车也变少了。但除此之外，我感到人们尽可能地维持了正常的生活。

如果你是一个被指派观察美国人行为的外星人，如果你的观察不是非常仔细的话，你不会觉得 2020 年的市容市貌跟 2019 年有什么明显区别。美国并不是正在经历战争的样子。绝大多数商家都照常营业，并没有变成断壁残垣。街头并没有硝烟，你不太可能看到有人走着走着就突然倒下死去了。人们散步、遛狗、逛景点、购物、为生活奔忙、偶尔集会示威，以前不也是这样吗？

你可能会漫不经心地在观察日志里写下：2020 年的最突出变化是，不知为什么，几乎所有人都戴上了口罩。

所以我能理解为什么有些美国人那么强烈地反对戴口罩。如果你不看数字，你确实感觉不到疫情的严重性。数字是抽象的，感受是具体的。如果不是我知道并且相信疫情的统计数字，我可能会认为这一切是一场闹剧。

有些认识只有数字能提供。然而如果只看数字，你又无法感知到每个当事人具体的感受。那我们到底应该如何对待统计数字呢？

咱们继续说蒂姆·哈福德的《让世界讲得通》这本书，这一讲的主题是个人经历和数字的关系。

### 统计数字与我何干？

哈福德现在住在伦敦。他在电台做了个节目叫《多点或少点》（More or Less），专门讲如何借助统计数字理解世界。每个人都需要正确理解数字，包括哈福德自己。

哈福德每天都要搭乘公共汽车和地铁上下班。他总感慨车里比沙丁鱼罐头还要挤，他心想伦敦的公共交通真是不行啊。然而伦敦交通部门发布的统计数字，却不是这样的。

统计显示，伦敦平均每辆公共汽车上的乘客只有12 人，伦敦地铁平均每个班次的乘客只有130 人。

你能想象吗？伦敦的公共汽车可是双层大巴，地铁有那么多车厢，才这么点人？那得多空啊。你见过伦敦有那么空的车吗？

当然实际情况是哈福德的通勤时间正好是早晚高峰，平时人少的时候他不在。但是这就给我们提出了一个问题，这种统计数字到底有啥意义呢？

如果一组数字的分布非常极端，你给个平均数没有太大意义。这就好比说因为高收入者的存在感太强，北京市的“平均工资”明显高于一般人的工资。不过我们谈论工资至少可以还用“中位数”取代“平均数”，中位数更能代表普通人的收入水平 —— 但是对公交和地铁来说，如果极端数值只出现在早晚高峰，中位数也会是一个很小的、没有代表性的数字。

这里的关键在于，交通部门计算平均人数是为了自己规划车次和核算成本，他们是以“车”为本，不是以人为本 —— 

「平均每辆车上有多少人」≠「平均每个人看到自己车上多少人」

交通部门并不在乎你感受到多少人。

这就引出了一个问题。统计数字，和你，到底有什么关系？你需要知道全世界总共有多少人口吗？你需要知道全中国所有人的收入的平均数或者中位数吗？真正跟你有关系的是来你开的那家餐馆吃饭的有多少人，是你所在行业的收入水平，而不是远在天边的东西，对吧？真正能影响你的是你能接触到的世界，是吧？

哈福德把宏观的、需要精确测算的统计数字叫做“慢统计”，把我们个人经历中取得的直观印象叫做“快统计”。换个说法，每个人的个人经历相当于“虫子的视角”，虫子住在洞里，只能看见一片很小的区域；而统计数字则相当于是“鸟的视角”，鸟在天上飞，可以看到很大一片区域。

那么问题就是，我们为啥需要慢统计和鸟的视角呢？

### 体验是有限的

我们每时每刻都处于切实的体验之中，但体验能给你提供的认知是有限的。哪怕你只关心“对自己有用的东西”，你也需要统计数字。

一个重要原因是有些效应只有统计能告诉你。

吸烟会导致癌症吗？这就是一个虫子视角回答不了的问题。肺癌患者毕竟是极少数，而吸烟的作用具有不确定性。可能你认识的一个肺癌患者恰好不抽烟，而你认识不少成天吸烟的人，他们都没得肺癌。

吸烟导致癌症，这是一个分散在人群之中，只有用鸟的视角才能发现的规律。事实是重度吸烟者得肺癌的可能性，比不吸烟的人高出16 倍。这是一个非常强的效应，对你要不要吸烟的决定非常有用，但是这个知识只能通过统计才能得到。

一种药物到底有没有效，疫苗到底有没有效，戴口罩到底有没有效，这些都得通过统计才能知道。你的经历只是一个点，必须把大量的点连起来才能看出来东西。

而且个人经历会误导人得出错误的结论。

哈福德举了一个例子，为什么西方有很多人相信接种 MMR 疫苗（一种能预防麻疹、流行性腮腺炎、风疹这三种疾病的疫苗）会增加儿童自闭症的风险？诊断自闭症有两个窗口期，一个是小孩 15 个月大的时候，一个是上学前。而 MMR 疫苗要打两针，恰好是在同样的时间段。那么这就导致很多家长带孩子接种了疫苗之后不久，正好去做自闭症诊断，发现孩子有自闭症。

这是一个结构性的巧合。要想知道是不是疫苗导致自闭症，我们必须借助大规模统计。有一项研究统计了 65 万个儿童，其中有些孩子打了疫苗，有些孩子没打 —— 他们有自闭症的比率都是 1%，所以疫苗跟自闭症没有关系。

还有，不看统计数字，你个人对世界的印象会非常错误。

现在我们了解世界的最大窗口已经不是个人经历了，而是媒体，特别是电视。但电视会误导你。电视上的人，通常来说，都比普通人富有、比普通人有名、而且比普通人好看。这样的印象会造成你对世界的错误判断，你会默默认为自己找对象就得找电视上常见的那种 —— 殊不知电视上常见不等于生活中常见。

心理学家对此有个专门的名词叫“天真的现实主义（naive realism）”。不看数字，直观的感受会让你很天真。特别是你要对社会问题发表意见，就会大错特错。哈福德引用了一项研究，你看你能不能对下面这些问题做个基本的判断 —— 

- 从2000 年到现在，各国的谋杀率是上升了还是下降了？
- 因为恐怖袭击而死亡的人数，是过去15 年多，还是从过去30 年到过去15 年间多？
- 发达国家患糖尿病的人数比例，大概是多少？

答案是谋杀率和死于恐怖袭击的人数都在显著下降，糖尿病患者比例只有 8% —— 而研究者的调查表明，多数人认为谋杀率和恐怖袭击在上升，平均认为有 34% 的人患糖尿病。这些偏见大多来自媒体，而媒体天生喜欢报道极端的、没有代表性的信息。

### 不能没有体验

那你说我干脆做一个强硬的数字主义者，我只看统计数字，不论个例，这好不好呢？这也不行。只看个人经验会让你以偏概全，而如果只看统计数字，你就会犯以全概偏的错误。

统计学的一个问题是，一旦形成指标，人们就会为了指标而行动，导致数字不但没有反映、而且会扭曲真实世界。比如说，某医院给医生制定的考核指标是手术成功率，谁成功率高就能获得奖金，那医生会怎么做呢？医生会故意不给重症患者做手术，因为重症患者的手术失败率高。

所以统计数字只有反映现实的意义，而不能用它来指导现实。现实是在每一个具体的经历中做出来的。

更重要的是，如果没有直观印象，我们其实并不知道数字意味着什么。

哈福德是专门写经济学相关话题的作家，他对经济数字极为敏感。哈福德完全知道，从1990 年以来，中国的人均实际收入增长了 10 倍；从 80 年代初以来，中国的极端贫困人口减少了 7.5 亿；中国最近三年消耗的水泥，比美国整个 20 世纪消耗的还要多。

如果你只看这些数字，你会认为中国是一个非常厉害的国家，中国经济在高速前进。但是你难以想象那到底是什么样的厉害和高速。中国三年消耗的水泥比美国一个世纪还多，这是一种什么状况呢？你要没去过中国，你没有概念。

后来哈福德本人真的到了中国。他从香港入境，到深圳，再坐高铁到广州，一路上看到到处都是现代化建筑，简直全是城市没有乡村，他才意识到那么多水泥到底是什么概念。他的思想受到巨大冲击，无数关于中国的问题扑面而来。

<center><strong>*</strong></center>

 **<span style="color: #E87321;">统计学的第二个法则是虫的视角和鸟的视角我们都需要。我认为最关键的是你任何时候都要意识到自己视角的局限性。你既不能只看个人体验，也不能只看统计数据，你得都看才行。</span>**

在现代世界这并不是做不到的。你可以带着统计数字到实地考察一番，你去美国各地走一走，去中国的大街小巷看一看，你会有更清楚的认识。

这个要点是只有数字还不行，你还得有“数字感”才行。你得知道那些数字意味着什么。

某某一个月收入这么多钱，你知道这是什么意思吗？像这样的数字感有时候你哪怕上上网也能获得。哈福德推荐了一个网站叫“美元街” ( https://www.gapminder.org/dollar-street )，这个网站专门收集了很多照片，告诉你世界各地的家庭，每月收入相当于多少美元，他们过的是什么样的日子。

非洲布隆迪的一个家庭，每月收入只有 27 美元，他们的日子是怎么过的？中国云南的一个家庭每月收入 1 万美元，他们又是怎么过的？看一看这些家庭生活的方方面面，你会对 27 美元和 1 万美元这两个数字产生更准确的认识。

我的感觉是 1 万美元不算太多 27 美元也不算太少，那两种日子的差距不是 370 倍。数字背后，是家家都在努力地生活。

> **划重点**	
> 
> 1.体验能给你提供的认知是有限的，有些效应只有统计能告诉你，个人经历会误导人得出错误的结论。体验是“虫的视角”。 
> 2.只看个人经验会让你以偏概全，但如果只看统计数字，你就会犯以全概偏的错误。统计数字只有反映现实的意义，而不能用它来指导现实。统计是“鸟的视角。 
> 3.统计学的第二个法则是虫的视角和鸟的视角我们都需要。任何时候都要意识到自己视角的局限性，你得都看才行。

## 3：统计是数学题还是语文题

统计学在技术上属于数学，但在实际应用中，我感觉它更偏向于政治、经济学科， **<span style="color: #E87321;">统计问题更像是语文题</span>** 。

你说一家公司的财务报表好不好看，难道是会计决定的吗？像记账这样的常规操作早就标准化了。只要你把数据搜集好，该用什么公式怎么计算你根本不用管，统计软件都是现成的。决定统计结果的不是计算方法，也不是操作软件的统计员小张，而是单位的领导。小张作为一个工具人的作用仅仅是他会“数数” —— 领导虽然不会数数，但是知道该数哪些数。

我们继续讲蒂姆·哈福德的《让世界讲得通》。有一天你打开英国的《卫报》，看见上面一个大标题写着「17 岁-19 岁的英国女孩，有1/5 都有过自残或自杀行为」。你一看太可怕了，还是上网吧，结果你打开手机又看到一个新闻标题「伦敦的谋杀率第一次超过了纽约」。这两个标题都是真实的，而且媒体没有说谎。

遇到这种标题，我们应该如何反应，才能有点领导气质呢？

你要考察这些统计数据的输入和输出。 **<span style="color: #E87321;">统计学的第三个法则是输入看定义，第四个法则是输出看情境。</span>**

### 1.输入看定义

那些统计数字，到底统计的是什么东西？这是最基本的问题，对吧？但这也是最容易被人忽略、最容易带来误解的问题。 **<span style="color: #E87321;">统计对象常常没有清晰的定义。</span>** 树上七个猴地上一个猴，其中怀孕一个猴，而且她下一秒就要生了，你说一共几个猴？该数哪个不该数哪个这条线，你并不好划。

哈福德做节目遇到了一组很奇怪的数字对比。近些年来，英国伦敦以外地区的出生婴儿死亡率，明显比伦敦市要高。这引起了人们的警觉，是不是伦敦以外地区的医疗水平不行了呢？结果不是。

这个事儿的关键在于，到底什么叫“婴儿死亡”。孩子从怀孕到出生大概需要 40 周，如果是 37 周之前出生就是早产，但早产婴儿也是婴儿。伦敦市的标准是 24 周就算是一个生命了，只要是 24 周之后死亡，就算作婴儿死亡；不到 24 周的死亡才叫做流产。

那你说这个 24 周的规定有啥道理呢？难道 23 周的胎儿就不是生命吗？他其实已经长成型会动了啊。英国在伦敦以外的医院，就把“婴儿死亡”的定义，划线到了 22 周。正是因为这个定义的差别，导致了两个地区的婴儿死亡率不同。

这个差距挺明显的。2010 年，美国的婴儿死亡率是千分之 6.1，芬兰是 2.3，人们因此纷纷指责美国，但是这里面也有定义不同的因素。美国医院普遍对婴儿的定义是 22 周。如果我们只看 24 周以后的婴儿死亡率，那么美国其实是 4.2，芬兰是 2.1，仍然有差距，但是差距没有那么大。

再比如开头那个标题，「17 岁-19 岁的英国女孩，有1/5 都有过自残或自杀行为」—— 我们首先得问什么叫“自残（self harm）或自杀”。仔细看那个研究，它统计的并不是那些女孩在过去一年之中有没有像割腕之类的自杀行为 —— 而是从小长到大这么多年来，只要有过任何自我伤害的行为都算：像什么扇自己耳光、烧伤自己的皮肤，滥用酒精、暴饮暴食、厌食症、甚至拔掉头发都算自残，只要那些女孩认为是自残就是自残。那你说五分之一算高吗？事实上如果你只统计自杀成功的比率，英国15-19 岁的女孩中，是每年、每十万人中才有 3.5 个人。

统计定义的这种模糊性非常容易被政客所利用。政客说“我们要加大力度……”，到底什么叫加大力度？是明年给增加拨款吗？比今年多多少？考虑通货膨胀吗？这些都不好说。

2017 年，一个英国政客提议，要在未来五年“冻结非技术移民”。这听着挺有道理，接收移民应该接收稀缺的高级人才，低端的工作机会应该留给本国人，挺好吧？可是什么叫“非技术移民”呢？你细看，政客给的定义是按照职业的年收入划线：如果这个职业的年薪低于 35,000 英镑就算非技术。

可是这合理吗？你要知道很多护士、小学老师、技术员、律师助理、包括一些化学家的收入都低于 35,000 英镑，这些可恰恰是英国需要的、真正的人才。结果 2020 年，英国真的宣布了移民限制，最终把线划在了 25,600 英镑。

数什么，决定了数数的结果。你说现在贫富差距变大，那到底什么叫富人，什么叫穷人？我们应该算总财产呢，还是算年收入？这两个统计结果的差别是巨大的。

再比如说，现在大家普遍认为新冠是比流感严重得多的病毒，但是也有些人认为新冠就是一场大流感，因为他们认为新冠的实际死亡率并不比流感高很多。这就涉及到到底怎么统计新冠肺炎的死亡率。死亡率 = 死亡人数／感染人数，可是什么叫“感染者”？无症状感染算不算感染？没去医院确诊、自己在家自愈的那些人要不要统计上？还有，当初统计流感的死亡率的时候用的是什么标准，这两个标准一样吗？这些已经不是医学问题了。

### 2.输出看情境

即便定义清楚，一个数字到底是大是小，我们还得看具体的情境才知道。那个新闻为什么说「伦敦的谋杀率第一次超过了纽约」呢？其实就一组数字：2018 年 2 月，纽约有 14 起谋杀案，而伦敦有 15 起，这是历史上第一次伦敦的谋杀案多于纽约。

那这对伦敦来说是多大的坏事呢？ **<span style="color: #E87321;">没有具体情境的数字就如同没有测量单位一样。</span>** 首先你得知道伦敦和纽约各自的人口数量，但是因为两个城市的人口差不多，直接比较数字是可以的。

然后你得考虑时间情境。是不是伦敦治安变差了呢？并不是。我们对比 1990 年全年，伦敦有 184 起谋杀案，纽约有 2262 起 —— 所以不是伦敦变差了，而是纽约变好了。更合理的说法是伦敦的治安一直都很好。

数字的情境包括时间尺度、空间尺度、总人口、GDP、财富总量等等。对这些常用的数字有个基本感觉，你就容易评估新闻里那些数字了。

这几天我刚看到一个非常有意思的例子。2020 年 12 月 31 日，纽约时报发表了一篇讲中国扶贫的文章，叫做《工作、房子和牛：中国代价高昂的“运动式脱贫” 》[1]。文章中列举了中国近年来扶贫取得的成就，但是记者表达了他的担心，他认为中国这种扶贫是不可持续的。

有意思的不是这篇文章本身，而是纽约时报读者的评论。我按点赞顺序排列看了大概几十条评论，所有这些评论 —— 注意不是“几乎”所有，是所有 —— 都支持中国、反对那个记者。从名字和语气可以看出来他们大多都是美国人，所以你看<u>美国也有愤青</u>。

而这些网友很善于看数字的情境。有好几个评论提到，中国五年间，在扶贫上总共花费了 7000 亿美元 —— 相当于中国GDP 的1% —— 而这些钱帮助了 5000 万人脱贫，相当于平均每人每年 600 美元，如果这叫不可持续，那请看：美国政府给富人减税一下子就减掉了 2 万亿美元，美国政府每年给 200 万农民发农业补贴要花去 200 亿美元，相当于每人每年 1 万美元，难道这才叫可持续吗？对比之下中国纳税人花的钱好像更值。

其实现在美国网友对中国的支持率远高于美国媒体，因为他们要拿中国说事儿，去反对美国政府。包括写那篇文章的记者，自己在推特上也说中国扶贫搞得好。那么问题来了，纽约时报为什么非得用批评语气谈论中国呢？为什么美国主流媒体总是报道中国的负面新闻呢？

以我之见，这并不是说西方媒体有什么同盟式的定要系统性地反华。事实上美国主流媒体上报道美国的负面消息更多。特别特朗普当政这四年，主流媒体就没好话，批美国比批中国狠得多。而这并不完全是媒体人有什么偏见 —— 这其实更是媒体的性质所决定的。

### 3.为什么新闻没有好消息？

**<span style="color: #E87321;">凡是为市场服务的新闻，报道的大多都是坏消息。坏消息会让人感觉更重要</span>** ，批评的语调会让纽约时报的读者感到更有深度。不过人并不是悲观动物，人是乐观动物。

哈福德说，如果你在伦敦街头随便拦住一个市民，问他对自己未来的经济状况是乐观还是悲观，他十有八九回答乐观。但如果你问他对英国整体的状况是乐观还是悲观，他很可能是悲观的。这显然是一个偏见，如果大多数英国人都认为自己的状况很乐观，为什么英国整体会很悲观呢？这其实是媒体造成的。

哈福德认为，媒体爱报道坏消息，并不是因为人们更喜欢坏消息 —— 而是因为人们更容易注意到坏消息，因为只有坏消息具有突发性和意外性。

好消息往往不值得报道。这是因为事情变好都是慢慢变好的。你说中国昨天减少了几万贫困人口，今天又减少了几万，这是新闻吗？读者想看的是意外事件。而意外事件往往是坏事件。

比如你设想一下，如果下一个小时之内，在你身上要发生一件值得上新闻的大好事，它会是什么呢？其实你现在已经挺好了，如果有什么疾病的话一小时之内也恐怕治不好。除了买彩票中大奖你很难想象有什么大好事能在一小时之内发生。但如果让你想象未来一小时内可能在你身上发生的坏事，那想象空间就大了，比如突然地震、天降陨石之类，简直什么事都有可能发生。 **<span style="color: #E87321;">坏消息和好消息是不对称的</span>** 。

所以我们看新闻里的统计数字一定要考虑时间情境，不要过分被短期波动影响。当你把视角放大、频率放慢，你看到的东西完全不同。

有人建议玩这么一个游戏：我们设想 2018 年出了这么一期报纸，它不是日报、周报也不是月报和年报，而是每 25 年才出一期，你说它应该写些什么呢？

它不会写那些鸡毛蒜皮，它写的大概是<u>中国崛起、互联网普及、智能手机出现</u>这三个主题。

那如果是 50 年出一期，它的首页标题大概<u>是「没有发生核战争！」</u>这是因为它得跟1968 年去对比，而当时正处于冷战。

而如果是 100 年、200 年才出一期，那么人们更关心的就是<u>科技进步、健康水平大大提高，贫困人数大大减少这些事情 —— 这些全都是好消息</u>。

**<span style="color: #E87321;">如果你喜欢好消息，你应该考虑更大的时间尺度。</span>**

输入看定义，输出看情境，视角和视野决定内容，这些难道不是语文题吗？

> **注释**
> 
> [1] https://www.nytimes.com/2020/12/31/world/asia/china-poverty-xi-jinping.html 

> **划重点**
> 
> 数什么，决定了数数的结果。一个数字到底是大是小，我们还得看具体的情境才知道。当你把视角放大、频率放慢，你看到的东西完全不同。
> 
> 统计学的第三个法则是输入看定义，第四个法则是输出看情境，视角和视野决定内容。

## 4：怎样像强者一样看科学论文

这一讲我们先播报几个你已经比较熟悉的事件的最新进展。

- 1）“嫦娥五号”带回来的 1731 克月球土壤，是人类第一次取得的月球背面的土壤。这个土壤跟之前美国和苏联的月球土壤有什么不同呢？其中有没有水的成分呢？有多少氦3呢？有没有什么令人感到特别意外的物质？答案是现在还不知道，因为科学家仍然在分析之中。
- 2）2020 年12 月23 日，一颗“火流星”在青海玉树坠落，科学家判断这是一块重达430 吨的陨石。你知道这颗陨石的奇特之处吗？根据科学家的计算，它的运行轨迹和坠落情况都符合陨石的行为规律，这是一颗正常的陨石。
- 3）最近新出了一本书叫《博弈论：决策致胜的法则》，其中讲到了博弈论的知识。不过这些知识我们专栏已经讲过了。
- 4）罗胖在跨年演讲中提到了几个有关中国经济的数字，其中特别有一项数字是 2019 年中国向外输出了 530 亿美元的钢材。而我查阅了一下，发现他说的对。
- 5）我没有感染新冠病毒的症状，所以我没有去做检测。
- …… 

听到这里你可能再也忍不住了。没料你说啥啊？确实，上面这些所谓的进展其实是没有进展，没有哪个媒体会向你报道这样的消息。但是请注意，这些都是正确的消息。

正确，但是不值得报道。意外的消息才值得报道。我为了写这个专栏每天都在寻找意外的消息，我希望今天人类收到了外星人信号明天有人终于证明了P=NP，我希望把专栏变成猛料发布会。

好在科学里的猛料也挺多的。我们最喜欢的是那些「意料之外，情理之中」的研究结果。最好你一听觉得特别新鲜有趣，仔细一想又能相信它是对的，然后最好它还有个普遍的应用。比如下面这些你可能已经耳熟能详的说法 —— 

- 1）「选择的悖论」。心理学家摆出一些果酱让受试者买。当可选的果酱只有 6 种的时候，30%的人从中做出了选择，而且真的花钱买了；可是当可选的果酱有 24 种之多的时候，只有 3%的人做出了选择。这个实验告诉我们，选项太多会让人陷入矛盾而干脆什么都不选。
- 2）「意志力是一种有限的资源」。如果你今天下午要面对一场意志力的考验，比如说考试，那你中午这顿饭最好吃得任性一点。这是因为强迫自己吃健康饮食会消耗你的意志力，而意志力是一种有限的资源，你应该留着用在下午的关键时刻。
- 3）「Prime 效应」。你知道吗？仅仅是阅读和使用一组有关“老年”的词汇，你就会收到暗示，感到自己变老了。受试者做了一组文字游戏题，题目中的答案都是像“脱发”、“退休”、“皱纹”、“灰色”和作为老年人度假胜地的“佛罗里达”这样的词，结果受试者做完题，离开房间往外走的时候，他们的走步速度，明显地比做别的题目的对照组要慢：他们不知不觉地把自己当成了老人。
- 4）「高能量姿态」。如果你马上要参加一场面试，感到自己有点不自信，可以先演练几个姿势。比如你可以像“神奇女侠”那样双腿分开挺身站立，然后双手叉腰。这样的姿势能给你正面的自我暗示，会让你变得更自信。
- 5）「逆火效应」。当我们面对一个谣言的时候，也许最好的办法是对它置之不理，而不是给它辟谣。有研究表明反驳一个谣言只会加强这个谣言的传播，而且过后人们会忘记它到底是对是错，可能会更容易记住错误的结论。

以上这五个研究结果，有的我们专栏讲过，有的你可能在别处看过，它们都非常、非常著名。然而你知道 **<span style="color: #E87321;">现在心理学陷入了“可重复性危机”</span>** ，有很多看似惊人的结果都经不起重复验证实验。那你能不能猜一猜，上述这五个研究中，有哪几个，未能经受得住重复验证，现在已经被基本上证伪了呢？

<center><strong>*</strong></center>

心理学家曾经组织过一次跨学校、跨机构的大规模协作，共同选择了 100 项已经发表的研究，对其进行重复验证。验证的结果是 2015 年发布的。你猜这100 个研究中，有多少个经受住了验证的呢？

只有 39 个。连一半都不到。科学结论的标准不就是可重复可检验的吗？可是你这里有超过一半的研究都是不可重复的。当然也许那些重复研究做的不准确，你得找很多研究组，各自做很多次才知道到底对不对。我们刚才说的那五个研究就是这样的情况，现在已经有多个组对它们做过重复验证，结论是相当一致的 —— 

那 **<span style="color: #E87321;">五项研究，全都被证伪了</span>** 。

具体的文献请参考蒂姆·哈福德的《让世界讲得通》。可这是为什么呢？难道说最早的那些研究者都是故意造假吗？

<center><strong>*</strong></center>

能用普通错误("愚蠢")解释的就不要用恶意，我们还是说统计学。这一讲的主题是 **<span style="color: #E87321;">“出版偏倚（publication bias），也叫发表性偏倚”。出版偏倚是幸存者偏差的一种，它使得你能看到的研究结果，都是比较怪异的研究结果。</span>**

发表学术论文和发表新闻报道一样，读者欢迎意外消息。如果你的论文主题是像我们今天开头的那五条报道一样，你根本找不到地方发表。做出正确的研究结果很容易，难处在于做出意外的研究结果。

假设你是一个心理学研究者。“人”这个动物的各种特性对你已经都不新鲜了，可是为了发表论文，为了在学术界生存下去，你必须找到人的一个新的、意外的特性。有一天逛超市的时候面对十几种果酱你不知道该选哪一种。在你妻子催促你的时候，你的灵感不期而至。

会不会选项越多，人就越不想选呢？

这个想法很新颖。有点反常识，同时又是那么的合理。从来没人想到过这个道理。而且这个道理还对商家有指导意义。你迅速组织了实验。

你非常希望这个效应是真的。

连你自己都没想到，这个实验将会被写进很多本畅销书里。

<center><strong>*</strong></center>

心理学实验通常都是招募一群人，随机分组，让各组做不同的事情，最后结果是统计出来的。而统计容易问题。接下来发生的事情有多种可能性。

结果可能仅仅是个巧合。也许你招募的受试者人数太少，也许就是那么巧，你观察到面对 6 个果酱选项的人明显比面对 24 个选项的人更愿意花钱。而殊不知，如果有一百个研究者做这样的实验，其中只有一个会得到你这样的结果。你其实是中奖了。

还可能你这个实验的组织有问题。这就好比说我们组织一场篮球比赛，山东对广东。你想证明山东强于广东，你给自己设定的标准是如果山东队的比分比广东队高十分以上，就算山东队更强。比赛进行到第二节第五分钟的时候，山东队领先广东十分 —— 你认为结果已经出来了，于是你就叫停了比赛，宣布实验结束。

更有可能是你对实验数据做了一定的修饰。对照组有几个人一上来也不看题就买了果酱，他们好像是专门来买果酱的，这样的人不能算数。实验组有个老奶奶犹犹豫豫地就是不买，于是你规定把七十岁以上的受试者都排除在外。反正规则都是你定的，你反复尝试了各种规则，终于定制了一组能让结果出现的规则。

在你看来这些都算不得造假，大家做实验统计都是这么做的，毕竟你没有胡乱编写数据。后来又有一次逛超市的时候，你也问过自己：如果我这个发现是对的，那些超市为什么还给每个商品弄那么多选项呢？你说服自己，这一定是他们还不懂消费者真正的心理。

你的论文发表了。

<center><strong>*</strong></center>

说到这里你可能会问，难道那些论文的审稿人就不好好把把关吗？这很难把关。期刊和审稿人都不可能专门组织一帮人把论文中的实验重做一遍，一般看你的研究方法没问题，结果新颖就行了。而论文发表之后，通常也不会有人专门做实验去验证你的结果。

这就是出版偏倚。验证别人的结果要花费同样的人力物力，可是验证的结果是不值得发表的。你说他做得对也好错也好，期刊不感兴趣。期刊只喜欢新的、意外的结果。

特别是，期刊不喜欢没有效应的结果。2008 年，有人系统性地调查了有关抗抑郁类药物的研究论文，发现 48 篇论文都是说某种药物有效的，只有 3 篇说某种药物无效。然而 48 : 3 远远不是真实的研究结果对比，你还得看那些被期刊拒稿没有发表出来的研究。调查者找出了 23 项没有发表的研究，其中 22 项说某种药物无效，只有 1 项说某种药物有效。再进一步，在那些发表出来的论文中，还有 11 项结果其实是药物无效，只是写论文的时候被粉饰成了有效 —— 把这些都考虑进来，真正的有效vs 无效比分应该是 38 : 37。

也就是说那些药物无效的可能性相当大。

我们开头说的那种「世上本无事」式的消息，才是普遍的消息。 **<span style="color: #E87321;">意外的消息常常是不可靠的消息。使用统计方法得出的科学结论很可能比主流媒体的新闻报道更不靠谱。</span>**

<center><strong>*</strong></center>

这让我们如何面对科学论文呢？以我之见，了解了科学家的复杂心态、科研工作中的各种不堪行为，你最大的收获应该是做一个心比他们更大的强人。他们关注的是自己那个小研究能不能发表，你关注的是那个结论正确不正确，是不是真有用。科学家不是让人仰望的神职人员，他们只不过是我们的工具人。

但我还是那句话，我们之所以相信科学，不是因为科学这门业务的方法绝对可信，而<u>是因为科学家这个群体很厉害</u>。首先并不是所有学科的论文都那么容易出毛病，通常只是涉及到统计学的研究才会有那么大的不确定性。其次我们「相信科学」信的不是哪一篇具体的论文，而是「学术共同体」的共识，信的是「当前科学理解」，而共识和理解都是经过大量重复验证的结论。

更重要的是，科学共同体非常善于自我更新和自我纠正。现在学术界已经采取了一系列措施去应对可重复性危机和出版偏倚 —— 

- 第一，科学家被鼓励重复验证现有的研究结果，而且鼓励发表。
- 第二，已经有了专门的期刊（比如说，Trials）用于不带偏见地发表统计实验结果 —— 不论这个实验结果是否有意外发现：你能证明某个东西没有效应，这也是值得了解的结论。
- 第三，现在流行一个新的研究规范是在开展一项随机实验之前，研究者必须先在某个网站注册一下（这叫 preregistration），事先说好你准备用什么方法、采集和分析哪些数据。这就等于说在篮球比赛开始之前先说好要打多少分钟，这样就避免了你根据比赛情况现场决定如何采集数据。
- 第四，有感于公众不容易了解当前科学理解，科学家成立了像 “科克伦协作（Cochrane Collaboration， https://www.cochrane.org/ ）”这样的组织，专门就一些新的像医学和社会科学领域的新进展撰写文章，给你一个最可信的说法。

**<span style="color: #E87321;">统计学的第五个教训是你有必要了解那些科研结果是怎么做出来的。</span>** 经常去餐馆的厨房看看不一定能增加你的食欲，但是能让你的认识更接近内行。

> **划重点**
> 
> 统计学的第五个教训是你有必要了解那些科研结果是怎么做出来的。经常去餐馆的厨房看看不一定能增加你的食欲，但是能让你的认识更接近内行。

## 5：审查「大数据」

2010 年，我曾经给《新知客》杂志写过一篇讲按现在说法叫「大数据」的文章，当时可能还没有「大数据」这个名词。我那篇文章叫《数字如潮人如水》（ https://ggw.tongji.edu.cn/index.php?classid=1110&t=show&newsid=8834 ），我说很多公司正在利用个人的数据判断消费心理。我说到一个例子是赌场根据一个老太太的输赢记录算出来了她的疼痛点，在她输太多的时候请她吃了牛排，避免她痛定思痛从此戒赌。

那篇文章引起了强烈的兴趣，还被中央电视台的一个读报节目播报了，我收获了几分钟的名望。那时候人们谈论「大数据」都是赞叹。当然我们也会想到这样的做法会不会伤害消费者利益，但是总体上，我们认为这很厉害。

现在十年过去，我们对「大数据」态度已经全变了。

有句话叫「如果你手里有一把锤子，你会看什么东西都是钉子」。以前我们谈论大数据都是想象自己是那个拿着锤子的人，我们谈论这把锤子好用不好用。

而现在，每个人已经切身领教了大数据，我们才意识到，其实我们是钉子。

<center><strong>*</strong></center>

**<span style="color: #E87321;">只要你能冷静思考，什么大数据、什么算法，不但一点都不神奇，而且可以说相当笨拙。</span>**

有一个你想必早听说过的故事是这样的。美国有个父亲发现 Target 超市给他女儿寄来一些孕妇用品的减价券，可是他女儿还在上高中啊！他非常生气，就打电话向超市抱怨，超市赶紧表示了道歉。结果不久之后，他发现女儿原来真的怀孕了。

这个故事是 2012 年出来的 [1]，当时传为美谈，人都说大数据太神奇了，比你身边的人更了解你。可是你仔细想想，这一点都不神奇。那个女儿在超市的购物记录里有一项是加了叶酸的维生素补充剂，而这个东西恰恰是国家卫生局建议孕妇服用的。如果这个父亲亲眼看见女儿在服用这个药，而且他了解这个知识，他难道猜不出来女儿可能怀孕了吗？

最大的可能性是超市那个派发减价券的算法根本不需要理解“怀孕”这个事儿，<u>它只是考虑了各种商品的关联习惯而已</u>。而且那个父亲提出的是个真问题：这些算法的匹配准确度并不高。超市既不可能、也不需要按照每个人的精确需求派发减价券，算法特意有一定的随机性。超市经理在电话里道歉并不仅仅是出于礼貌，他完全知道算法不准。

可如果不是推荐商品，而是选拔人才呢？如果是考核呢？如果是决定犯罪嫌疑人是否能得到保释呢？算法的准确度可就是个大问题了。

我们继续说蒂姆·哈福德的《让世界讲得通》，这一讲的主题是大数据算法的两个问题，一个是数据采样不准，一个是算法不透明。

<center><strong>*</strong></center>

最近有一部根据同名网络小说改变的电视剧叫《赘婿》，还没播出就成了微博的热点，不过可能不是主创人员想要的热点。

人们指责男主人公，明明是给人家当赘婿出身，靠着女方的家产做大，结果还找了那么多妻妾，实在是太不尊重女性了 [2]。小说作者愤怒的香蕉的一番话更是激怒了女观众：「七年前我写《赘婿》的时候根本没考虑女读者啊，……本来就是男频爽文……为什么有女观众觉得剧需要她们？」

这句话生动地说明了<u>大数据算法的采样偏差</u>。如果读小说的都是男性，看电视剧的都是女性，你怎么办。这个现象绝非特例，而且绝非只在中国。

美国警用防弹背心的设计没考虑到女警察有乳房。苹果健康应用没考虑到女性生理周期。绝大多数药物的临床测试都有意避开了孕妇和哺乳期女性。就连美国刚刚批准的两个mRNA 新冠疫苗，用了好几万人做临床三期实验，其中也没有孕妇。如果你的数据采样有系统性的偏差，数据再多也不可能准确。

而默默的忽略就等于默默的歧视。2014 年，亚马逊公司决定用大数据算法挑选应聘者的简历。这个思路听起来没毛病：我先看看我现有的优秀员工当初的简历都是什么样的，我让算法自动从这些简历中学习规律，然后按照这个规律去筛选新的简历。一切都很公正，是吧？

结果女性应聘者吃了大亏。当时亚马逊的优秀员工中，绝大多数都是男性。算法观察到了这一点，而且自动强化了这一点。如果你是一个女应聘者，哪怕你擅长一些传统上男性擅长的活动，比如你曾经入选过足球国家青年队，或者你曾经是国际象棋俱乐部的队长 —— 但是只要你的简历上写的是你是*女*足队员、*女子*国际象棋俱乐部队长，你也会被算法降级。

亚马逊一直到 2018 年才停止使用这个算法，而我们不知道有多少女性因为这个算法失去了机会。

**<span style="color: #E87321;">算法想不到的地方，人可以想到，而且我们可以做好。</span>** 上世纪七十年代，英国的儿童福利是以给家庭收入退税的方式发放的，而既然家庭主要收入通常来自男性，这笔钱往往就没有落到女性手上。后来英国政府意识到这是一个默默的歧视，于是改变做法，把儿童福利直接发给女性 —— 结果有经济学家注意到，女性和儿童服装的销量立即上升，男性服装的销量立即下降了。

为什么针对选举的民意测验经常不准？为什么商品销售的预测经常不对？问题往往不是出在数据量太少，而是出在数据采样的偏差。有的人不愿意接电话，不愿意填表告诉你他喜欢什么，有的人根本说不清自己喜欢什么，有的人说的跟他做的正好相反，有时候读小说的和看电视剧的是两种人。<u>在大数据之外还有一个“暗数据” —— 那些你测不到的人的数据。你测不到他们，你的算法对他们就没有代表性，可是他们却能影响大局。</u>

<center><strong>*</strong></center>

**<span style="color: #E87321;">现在算法的另一个问题，也可能是更有“体制”味道的问题，是不透明。</span>** 算法有毛病很正常，我们完全可以把它拿过来审视一番，找到毛病，提出意见。

华盛顿市使用一个叫做 IMPACT 的算法评估公立学校系统的教师表现，而且搞得非常强硬：如果算法认为哪个教师的表现不合格，她真的就会被解雇。结果是这个算法冤枉了很多好教师。

算法的逻辑很简单。美国学校是一个老师只教一个年级，也就是说她每次都是跟一个班的学生一年。算法考察这个班全体学生在上一个学年结束时候的成绩，再看看他们在本学年结束时候的成绩，两相比较，如果学生们的相对水平没进步反而还退步了，那就是这个老师没教好。你能不能想一想，这个算法可能会出什么问题。

2011 年，华盛顿式的学校系统用这个算法解雇了 206 个教师。这是非常粗暴的决定。

一个问题是学生表现有很大的不确定性。一个班总共才有不超过 30 个学生，这个样本量是非常小的。只要有那么几个学生在之前的考试中超常发挥、有几个学生在之后的考试中发挥失常，老师的前途就完了。学生可能因为家庭原因、因为校外原因，或者纯粹就是偶然地有各种发挥，这是老师控制不了的。

更大的问题在于老师可以作弊。如果六年级老师使用作弊方法大幅度提高了学生的成绩，七年级老师就等于接手了一个名义上的“天才班”，那她怎么办呢？

像这样的事儿，你必须充分了解那个算法，才可能给老师鸣冤。然而现在各个公司对招聘也好、广告推送也好、股票交易也好，各种算法都是保密的。以前如果你应聘落选了，也许还可以打电话问问对方为啥不要你；现在可能是连负责招聘的领导都想不到，你是因为简历里提到自己曾经是女足运动员而落选。

<center><strong>*</strong></center>

此时此刻，大型互联网公司正在中国遭受前所未有的猛烈质疑。人们不再赞叹他们提供的方便和平台，而是指责他们利用自己的垄断地位搞「大数据杀熟」、搞算法引流、搞有针对性的虚假广告。公众正在变得不再信任算法。

这些公司应该怎么做，才能赢回信任呢？

也许唯一的出路是把算法公开，或者最起码也要大大提高那些算法的透明度，让公众审查。

英国国家学术院院长，也是上议院议员，也是一位哲学家，奥诺拉·奥尼尔（Onora O’Neill），提出一个概念叫“智能开放（intelligently open）”。她认为智能开放的算法决策应该满足下面这四条要求 —— 

- 其中的信息是可获得的（accessible），不能藏在暗处；
- 决策过程是可理解的（understandable）；
- 信息是可用的（usable），比如说格式得统一；
- 决策结果是可评估的（assessable），也就是允许别人事后评估这个算法有没有做出不公正的决定。

其实这四点是可以做到的，而且做到了也并不会伤害公司的竞争力。我们专栏以前讲过一个案例 [3]，美国 NorthPointe 公司弄了个预测犯人被释放后再犯罪率的算法，叫COMPAS。因为这个算法预测黑人的再犯罪率普遍比白人高，有人指责其中有种族歧视。NorthPointe 公司并没有公开这个算法，但是大致让人了解了算法的逻辑过程，而且提供了非常详尽的训练算法和算法预测结果的数据。

结果很多专家主动研究了那些数据，他们不但证明了那个算法没有歧视黑人 —— 因为算法根本就没考虑犯罪分子的种族 —— 而且还从统计学上证明，不管是什么算法，要想准确预测再犯罪率，黑人就一定会吃亏。

我看那个公司是这次公开评议的受益者。其实你就算把算法全部公开，竞争对手也不太可能拿去就用，因为你的算法肯定是为你这个公司的特殊业务定制的。而且你不用完全公开，只要能做到“智能开放”，把算法放到阳关下让人审查，就可以赢得信任。

**<span style="color: #E87321;">统计学的第六个教训是问题：采样可能会有偏差；第七个教训是解决方案：算法应该开放。当你拿把锤子睨视天下的时候，别忘了钉子可能会反抗。</span>**

<div align="center">
  <img src="S4/imgs/page2167_img001.png" alt="- 你负责什么研究工作？ - 被人家研究！" width="500" />
  <p style="margin: 5px 0; font-size: 14px; color: #666;">- 你负责什么研究工作？ - 被人家研究！</p>
</div>

> **注释**
> 
> [1] Charles Duhigg, How Companies Learn Your Secrets, The New York Times Magazine, Feb. 16, 2012. 
> [2] 公平而论，《赘婿》原著小说对女性角色是相当尊重的。我读过一点，其中有政治、商业和武侠元素，还抒发了治国理念，的确是男性视角。后来之所以弃书，是因为我感觉作者的情感描写过于细腻……
> [3] 一道烧脑的“歧视”题

> **划重点**
> 
> 统计学的第六个教训是问题：采样可能会有偏差；第七个教训是解决方案：算法应该开放。当你拿把锤子睨视天下的时候，别忘了钉子可能会反抗。

## 6：比「狐狸」厉害的人

蒂姆·哈福德的《让世界讲得通》这本书总共说了十个统计学教训，我们前面已经讲了七个。 **<span style="color: #E87321;">第八个教训是统计机构一定要保持自己的独立性和中立性，应该只为事实而不为权力服务。第九个教训是图形往往比数字更有说服力。</span>** 这两个道理都很明显，因为专栏有「出版偏倚」，咱们就不细说了，最后这讲咱们直接说第十个教训。

**<span style="color: #E87321;">第十个教训是保持开放的心态。</span>** 这句话听起来是老生常谈，但是开放心态恰恰要求你不要老生常谈。这里面有真功夫。

<center><strong>*</strong></center>

你想必知道一个典故叫「狐狸与刺猬」。这本是哲学家以赛亚·柏林发明的一个比喻：狐狸知道很多小事，而刺猬知道一件大事。后来心理学家菲利普·泰特洛克（Philip Tetlock）搞了一项历时将近二十年的研究，证明像政治学家、智囊和外交官这样的所谓政治问题专家，对政治事务的预测准确度，并不比普通人更高 —— 其中只有一个例外，那就是狐狸型专家。泰特洛克 2005 年出了本书叫《狐狸与刺猬：专家的政治判断》，说狐狸型专家的预测准确率明显高于刺猬型专家，从此“狐狸”就成了学者的榜样。

我特别想提醒你的是，所谓狐狸型专家，绝非仅仅是“什么都懂一点”的人。博而不精并不是优点。你要想在学界立足，必须系统性地掌握一两门学问。你得有点刺猬精神，深耕一个领域，练就一身硬功夫，遇到事情才能拿出好主意来。我们不能读那么多书就学会一个“啊，我是狐狸，所以我什么都不信。”一根筋的专家固然不是好的预测者，但是比只会怀疑一切的人有用多了。

**<span style="color: #E87321;">用做预测的方法考教专家其实不太公平，专家的作用是遇到事情能拿方案拿主意而不是做预测，正如球星也不会预测比赛，但是球星很有用。</span>** 那怎么才能既有专家的本事，又能预测准确呢？

从 2011 年开始，泰特洛克又搞了一项关于预测的研究。这回是直接招募世界各地的专家和爱好者参加预测比赛。你需要对真实世界中正在进行的一些紧迫问题做出预测，而只要事情还没尘埃落定，你可以随时登录比赛官网，对自己的预测进行修改。泰特洛克在这项研究中也发现了一个群体，他们的表现远远好于其他人。2015 年，泰特洛克又出了一本书，叫《超预测：预见未来的艺术和科学》，专门描写了这个群体。

这个群体身上的特点比之前那个研究发现的“狐狸”更为突出。他们被泰特洛克称为「超级预报员（superforecasters）」。

超级预报员有四个关键特点。

<center><strong>*</strong></center>

第一个特点是，超级预报员都是 **<span style="color: #E87321;">从“基础比率（base rate）”出发去做预测</span>** 。基础比率这个概念是丹尼尔·卡尼曼提出来的，我们专栏前面讲过 [1]。所谓基础比率，就是这件事儿一般的概率是多少。

比如你要判断一对新婚夫妇将来会不会离婚，最好的办法不是先看你对这对夫妇了解多少，而是先看看现在像他们这样的夫妇，一般的离婚比率是多少。人们总觉得自己是特殊的，其实人与人之间的相同点远大于不同点。基础比率给你的预测提供了一个非常靠谱的参照物。从这个比率出发，根据当事人的具体情况稍作调整，是个好办法。

泰特洛克发现，哪怕你仅仅是给参赛者搞个一小时的“基础比率方法”培训，都能大大提高他们的预测水平。

超级预报员的第二个特点是 **<span style="color: #E87321;">对自己的预测结果有一个记录</span>** 。这听起来是非常基本的一步，但是很少有人能做到。

当你买下一只股票的时候，你会做一个记录，写下自己为什么买，对它未来的涨势有什么预测吗？等到这只股票跌到你不得不割肉的时候，你会找到当初的记录，反思自己的预测吗？有反馈才能有进步，但是人们总是不愿意回顾自己的失败。

第三个特点是 **<span style="color: #E87321;">频繁更新预测</span>** 。超级预报员密切地关注着事情的进展，他们会经常回来，登录网站更新预测。这听起来像是致胜的一手，毕竟随着事态发展，各种趋势的概率一直在变动，如果比分已经 2:0 了你都不愿意把平局的预测改成赢球，你肯定不是个好的预报员。

但频繁更新并不是绝对的致胜特点。哪怕是对于那些只有一次机会、不能更改预测的比赛，超级预报员的表现也是明显更好。

起决定性作用的是他们的第四个特点， **<span style="color: #E87321;">愿意改变自己的想法</span>** 。对一般人来说自己的观点是要捍卫的，对超级预报员来说观点是要检验的。

观点应该随着事实发生改变 …… 你要不是专家，这句话听起来真的很简单 —— 那是因为你根本没有观点。只有专家，才能体会到改变观点有多难。

泰特洛克的发现就说到这里。接下来换回哈福德，他说了两个经济学家的例子，一个是约翰·凯恩斯（John Keynes, 1883－1946），一个是欧文·费雪（Irving Fisher, 1867－1947）。

<center><strong>*</strong></center>

凯恩斯无需介绍。费雪是跟凯恩斯同时期的经济学家，他对现代人的影响力显然不如凯恩斯，但是他对经济学这门学问的贡献可能不亚于凯恩斯。费雪是计量经济学的开创者之一。他推崇数据和统计学，追求理性的决策。他是用科学方法指导健康生活的开创者，可以说是最早的生活黑客。他把自己关于宏观经济学的研究结果商业化，把自己对经济的预测向媒体出售。

<div align="center">
  <img src="S4/imgs/page2171_img001.png" alt="费雪" width="300" />
  <p style="margin: 5px 0; font-size: 14px; color: #666;">费雪</p>
</div>

在费雪和凯恩斯都活着的那个年代，人们认为他俩是齐名的经济学家，他们在老百姓之中有同样多的粉丝。那为什么后来凯恩斯越来越红，费雪的声望降级了呢？

我们多次讲过<u>一个心理学现象叫“峰终定律”，一个人一生的结局，往往决定了世人对他的评价。</u>作为经济学家，凯恩斯和费雪都曾经亲自下场炒股，而且两人都取得过很好的成绩，都赚过很多钱。但是对比之下，费雪的结局很不好：在 1929 到 1932 年的美国大股灾之中，费雪当退不退一意孤行，陷入愿望思维，不但输光了钱，还欠了一身债。

这可不是经济学家该有的水平。费雪在之后继续搞学术研究，晚年还写了一本分析大萧条的书，他的学术声望保住了，但是他的公众形象完了。要知道你以前可是教人炒股的大师啊。

你可以想见，费雪是一只刺猬。费雪的确非常固执 —— 但是凯恩斯也是刺猬啊，凯恩斯也很固执，凯恩斯不接受批评。可是凯恩斯炒股的结局就很好，这是为啥呢？

哈福德说，仅就炒股这件事儿而言，凯恩斯和费雪的做事风格有三个重大区别。

第一，凯恩斯曾经遭受过多次投资失败，而费雪是一路成功走来的。

两人都没有预测到 1929 年的大崩盘，但是他们的反应很不一样。凯恩斯失败过，他知道自己这次可能又看错了，所以他愿意承认失败，改变策略。而费雪在此之前对宏观经济的判断从来没错过，他非常自信。

第二，凯恩斯可以改变策略，而费雪不能。

凯恩斯曾经认为自己可以预测经济周期，当他经历过几次失败之后，干脆就放弃了预测。他的新策略是干脆不管宏观经济了，选几个好公司，买了他们的股票就拿着不动 —— 你看这不就是“价值投资”吗？事实上巴菲特很爱引用凯恩斯的话。

可是费雪不能改变策略，因为费雪有偶像包袱。费雪对宏观经济的预测是直接卖给公众的，粉丝已经认准你了，你得有 skin in the game 啊，你不能变。

第三，也是最深刻的区别在于，费雪坚信未来是可以预测的。

费雪认为一切都应该服从逻辑和理性，经济就应该服从他的理论模型。费雪是个什么人呢？他 1915 年出过一本畅销书叫《如何生活：基于现代生活的健康生活规则》（How to Live: Rules for Healthful Living Based on Modern Science），这本书里连日光浴的持续强度和时间、连吃饭的时候怎么咀嚼、连走路的时候每只脚向外的角度都给你规定得清清楚楚。

凯恩斯虽然也很强势，但是毕竟还（被传说）说过「当事实改变了，我就改变想法」这样的话。

费雪是不会改变想法的。

<center><strong>*</strong></center>

所以哈福德说的 **<span style="color: #E87321;">第十个教训是你得允许自己改变想法</span>** 。可是我们怎么才能从愿望思维和确认偏误里跳出来，怎么才能说服自己去接受不一样的想法呢？

耶鲁大学研究者丹·卡汉（Dan Kahan）曾经做过一系列关于确认偏误的研究。他跟此前的研究者一样，发现人们分析一个什么事物，常常是往符合自己的政治理念的方向分析。他还发现<u>专业知识并不能让人摆脱偏见，专业知识越强的人反而可能越爱捍卫自己的观点</u>。但是在 2017 年，卡汉和合作者找到了逃离这个思维陷阱的解药 [3]。他们发现，有一种特点，凡是有这个特点的人，就不会陷入确认偏误。

这个特点是 **<span style="color: #E87321;">「科学好奇心（science curiosity）」</span>** 。好奇心强的人喜欢打听对方阵营的人是怎么想的。他们越打听就越互相了解，越互相了解就越减少隔阂。你要是说的有道理，他们可能会改变自己的观点，接受你的观点。

好奇心强的人平时喜欢纪录片而不是明星八卦节目。他们读自己专业以外的科学书籍。他们非常喜欢那些带给人惊讶的、挑战世界观的话题。面对矛盾，他们不但不焦虑，而且还觉得很有意思。

所以要有开放头脑，要不做费雪，要成为一个比狐狸更厉害的人，你最应该有的品质是好奇心。

我们以前讲过，好奇心是学习的调控器 [4]，好奇心的大小是由“你想知道的知识”和“你现在已经知道的知识”之间的那个差距决定的。这么说的话好奇心产生的条件相当苛刻 —— 

首先<u>你得有一定的知识，然后你还得想知道别的知识。你得有观点，然后你还得关心不一样的观点。自己没有观点的人对*一切*观点都不在乎；只信一种观点的人对*别的*观点都不在乎。只有好奇心，能让你不是这两种人。</u>

要这么说的话，我们喜欢能提供意外的新闻其实是个好品质：说明你很懂，而且说明你在乎。

> **注释**
> 
> [1] 用别人预测自己
> [2] 《见机》5. 最好的结局
> [3] D. M. Kahan, A. Landrum, K. Carpenter, L. Helft and K. Hall Jamieson, ‘Science Curiosity and Political Information Processing’, Political Psychology, 38, 2017, 179–99, https://doi.org/10.1111/pops.12396 
> [4] 我们如何学习7：“积极”是多积极？

> **划重点**
> 
> 统计学的第十个教训是保持开放的心态。首先你得有一定的知识，然后你还得想知道别的知识。你得有观点，然后你还得关心不一样的观点。自己没有观点的人对*一切*观点都不在乎；只信一种观点的人对*别的*观点都不在乎。只有好奇心，能让你不是这两种人。

## 总结：统计学的十个法则



